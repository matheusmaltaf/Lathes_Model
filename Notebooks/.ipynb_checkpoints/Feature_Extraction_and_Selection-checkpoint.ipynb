{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction and Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import tsfresh\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tsfresh.feature_extraction.settings import from_columns\n",
    "from tsfresh.feature_selection.relevance import calculate_relevance_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *input_id* corresponds to the dataset used in this analysis. (See *Input* directory for more information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_id = 1\n",
    "\n",
    "PATH = '../Input/Input_%i.csv' %(input_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = np.genfromtxt(PATH,delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Shape: (444000, 9)\n",
      "------------------------------\n",
      "Number of Time Series: 592\n",
      "    Adequate Condition: 352\n",
      "    Inadequate Condition: 240\n",
      "------------------------------\n",
      "Measurments per Time Serie: 750\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "n_measures = int(full_data[:,1].max())\n",
    "n_timeseries = int(full_data[:,0].max())\n",
    "\n",
    "inadequate_condition = int(full_data[:,-1].sum()/n_measures)\n",
    "adequate_condition = n_timeseries - inadequate_condition\n",
    "\n",
    "\n",
    "print(30*'-')\n",
    "print('Shape:', full_data.shape)\n",
    "print(30*'-')\n",
    "print('Number of Time Series:', n_timeseries)\n",
    "print('    Adequate Condition:', adequate_condition)\n",
    "print('    Inadequate Condition:', inadequate_condition)\n",
    "print(30*'-')\n",
    "print('Measurments per Time Serie:', n_measures)\n",
    "print(30*'-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split between Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Train shape: (310500, 9)\n",
      "    Number of Time Series: 414\n",
      "        Adequate Condition: 246\n",
      "        Inadequate Condition: 168\n",
      "------------------------------\n",
      "Test shape: (133500, 9)\n",
      "    Number of Time Series: 178\n",
      "        Adequate Condition: 106\n",
      "        Inadequate Condition: 72\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "index = full_data[::n_measures,0].astype(int) - 1\n",
    "target = full_data[::n_measures,-1]\n",
    "\n",
    "L, W = full_data.shape\n",
    "\n",
    "train_idx, test_idx, train_target, test_target = train_test_split(index, target, test_size=.3, \n",
    "                                                                  stratify=target, random_state=12)\n",
    "train_idx.sort()\n",
    "test_idx.sort()\n",
    "\n",
    "L_train = train_idx.shape[0]\n",
    "train_index = np.zeros(L_train*n_measures, dtype=np.int32)\n",
    "for ii in range(L_train):\n",
    "    train_index[ii*n_measures:(ii+1)*n_measures] = list(range(train_idx[ii]*n_measures,\n",
    "                                                                (train_idx[ii]+1)*n_measures)) \n",
    "L_test = test_idx.shape[0]\n",
    "test_index = np.zeros(L_test*n_measures, dtype=np.int32)\n",
    "for ii in range(L_test):\n",
    "    test_index[ii*n_measures:(ii+1)*n_measures] = list(range(test_idx[ii]*n_measures,\n",
    "                                                                (test_idx[ii]+1)*n_measures)) \n",
    "    \n",
    "train_data = full_data[train_index,:]\n",
    "test_data = full_data[test_index,:]\n",
    "\n",
    "train_inadequate_condition = int(train_data[:,-1].sum()/n_measures)\n",
    "train_adequate_condition = int(train_data.shape[0]/n_measures - train_inadequate_condition)\n",
    "\n",
    "\n",
    "test_inadequate_condition = int(test_data[:,-1].sum()/n_measures)\n",
    "test_adequate_condition = int(test_data.shape[0]/n_measures - test_inadequate_condition)\n",
    "\n",
    "print(30*'-')\n",
    "print('Train shape:',train_data.shape)\n",
    "print('    Number of Time Series:', int(train_data.shape[0]/n_measures))\n",
    "print('        Adequate Condition:', train_adequate_condition)\n",
    "print('        Inadequate Condition:', train_inadequate_condition)\n",
    "print(30*'-')\n",
    "print('Test shape:',test_data.shape)\n",
    "print('    Number of Time Series:', int(test_data.shape[0]/n_measures))\n",
    "print('        Adequate Condition:', test_adequate_condition)\n",
    "print('        Inadequate Condition:', test_inadequate_condition)\n",
    "print(30*'-')\n",
    "\n",
    "np.savetxt('Subsets/Input_{}_Train.csv'.format(input_id), train_data, delimiter=',')\n",
    "np.savetxt('Subsets/Input_{}_Test.csv'.format(input_id), test_data, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>time</th>\n",
       "      <th>voltage_A</th>\n",
       "      <th>voltage_B</th>\n",
       "      <th>voltage_C</th>\n",
       "      <th>current_A</th>\n",
       "      <th>current_B</th>\n",
       "      <th>current_C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.456</td>\n",
       "      <td>0.524823</td>\n",
       "      <td>0.366407</td>\n",
       "      <td>0.715490</td>\n",
       "      <td>0.347956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.478873</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.539007</td>\n",
       "      <td>0.292153</td>\n",
       "      <td>0.718299</td>\n",
       "      <td>0.579262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.485915</td>\n",
       "      <td>0.448</td>\n",
       "      <td>0.539007</td>\n",
       "      <td>0.414721</td>\n",
       "      <td>0.693820</td>\n",
       "      <td>0.622134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.478873</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.546099</td>\n",
       "      <td>0.467250</td>\n",
       "      <td>0.290128</td>\n",
       "      <td>0.393154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.478873</td>\n",
       "      <td>0.448</td>\n",
       "      <td>0.546099</td>\n",
       "      <td>0.421855</td>\n",
       "      <td>0.646870</td>\n",
       "      <td>0.262213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  time  voltage_A  voltage_B  voltage_C  current_A  current_B  current_C\n",
       "0  1.0   1.0   0.500000      0.456   0.524823   0.366407   0.715490   0.347956\n",
       "1  1.0   2.0   0.478873      0.440   0.539007   0.292153   0.718299   0.579262\n",
       "2  1.0   3.0   0.485915      0.448   0.539007   0.414721   0.693820   0.622134\n",
       "3  1.0   4.0   0.478873      0.440   0.546099   0.467250   0.290128   0.393154\n",
       "4  1.0   5.0   0.478873      0.448   0.546099   0.421855   0.646870   0.262213"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split dataset in 3 parts\n",
    "info = train_data[:,0:2] # [id, time]\n",
    "data = train_data[:,2:-1] # [Voltage A, Voltage B, Voltage C, Current A, Current B, Current C]\n",
    "target = train_data[::n_measures,-1] #[target]\n",
    "\n",
    "# Normalizing each column within (0,1)\n",
    "scaler = MinMaxScaler()\n",
    "data = scaler.fit_transform(data)\n",
    "\n",
    "columns = ['id', 'time', 'voltage_A', 'voltage_B', 'voltage_C', 'current_A', 'current_B', 'current_C']\n",
    "df = pd.DataFrame(np.concatenate((info,data), axis=1), columns=columns)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 20/20 [09:36<00:00, 28.83s/it]\n"
     ]
    }
   ],
   "source": [
    "extracted_features = tsfresh.extract_features(df, column_id=\"id\", column_sort=\"time\", n_jobs=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking NaN Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Number of Features:  4722\n",
      "Number of Valid Features:  4701\n",
      "Number of Invalid Features:  21\n",
      "------------------------------\n",
      "Percentage of Valid Features:  99.555273%\n",
      "Percentage of Invalid Features: 0.444727%\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "features = extracted_features.columns\n",
    "\n",
    "nan_columns = []\n",
    "valid_features = []\n",
    "for col in features:\n",
    "    if extracted_features.loc[:,col].hasnans:\n",
    "        nan_columns.append(col)\n",
    "    else:\n",
    "        valid_features.append(col)\n",
    "\n",
    "print(30*'-')              \n",
    "print('Number of Features: ', len(features))\n",
    "print('Number of Valid Features: ', len(valid_features))\n",
    "print('Number of Invalid Features: ', len(nan_columns))\n",
    "print(30*'-')\n",
    "print('Percentage of Valid Features:  {:.6f}%'.format(len(valid_features)*100/len(features)))\n",
    "print('Percentage of Invalid Features: {:.6f}%'.format(len(nan_columns)*100/len(features)))\n",
    "print(30*'-')\n",
    "\n",
    "valid_features_dict = from_columns(valid_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = extracted_features.drop(nan_columns, axis=1)\n",
    "y = pd.Series(target, index=X.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevance_table = calculate_relevance_table(X, y)\n",
    "\n",
    "relevant_features = relevance_table[relevance_table.relevant].feature\n",
    "\n",
    "selected_features = X.loc[:, relevant_features]\n",
    "\n",
    "# Extracting the selected features dictionary from pandas data frame\n",
    "kind_to_fc_parameters = tsfresh.feature_extraction.settings.from_columns(selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Number of Extracted Features:  4722\n",
      "Number of Selected Features:  994\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(30*'-')\n",
    "print('Number of Extracted Features: ', len(features))\n",
    "print('Number of Selected Features: ', selected_features.shape[1])\n",
    "print(30*'-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving files for next stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Kernel/scaler__{}.pkl'.format(input_id), 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "with open('Kernel/valid_features_dict__{}.pkl'.format(input_id), 'wb') as f:\n",
    "    pickle.dump(valid_features_dict, f)\n",
    "    \n",
    "with open('Kernel/final_target_{}.pkl'.format(input_id), 'wb') as f:\n",
    "    pickle.dump(target, f)\n",
    "    \n",
    "with open('Kernel/kind_to_fc_parameters_{}.pkl'.format(input_id), 'wb') as f:\n",
    "    pickle.dump(kind_to_fc_parameters, f)\n",
    "    \n",
    "with open('Kernel/columns_{}.pkl'.format(input_id), 'wb') as f:\n",
    "    pickle.dump(selected_features.columns.to_list(), f)\n",
    "    \n",
    "with open('Kernel/selected_features_{}.pkl'.format(input_id), 'wb') as f:\n",
    "    pickle.dump(selected_features, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
